{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **03 - Correlation Analysis and Visualization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Analyze relationships between house attributes and the target variable `SalePrice` to identify key predictors for modeling.\n",
        "* Validate hypotheses by performing correlation analysis and visualizing the results.\n",
        "* Generate insights through visualization such as heatmaps, scatterplots and boxplots to demonstrate the strength and direction of relationships.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* Cleaned dataset: `outputs/datasets/cleaned/house_prices_cleaned.parquet`\n",
        "* Hypotheses that can be found in [Hypotheses and Validation Process in README.md](LÄGG IN LÄNK!)\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Generate reusable code that answers **Business Requirement 1** by analyzing correlations and creating visualizations.\n",
        "    * The code will also be used in the Streamlit app.\n",
        "* Create and save data plots in `docs/plots` directory for use in Streamlit app.\n",
        "* Identify and document the most relevant variables for the regression model based on the correlation analysis.\n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* The visualization in this notebook will also be used in the final dashboard to meet **Business Requirement 1**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "## Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chdir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "## Section 1: Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the cleaned dataset from `outputs/datasets/cleaned/house_prices_cleaned.parquet` into DataFrames and display the first five rows of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_parquet(\"outputs/datasets/cleaned/house_prices_cleaned.parquet\")\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "## Section 2: Data Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We create a data profiling report for exploratory data analysis (EDA) of the DataFrame `df`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ydata_profiling import ProfileReport\n",
        "\n",
        "profile_report = ProfileReport(df=df, minimal=True)\n",
        "profile_report.to_notebook_iframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 3: Correlation and PPS Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Our dataset includes four categorical variables stored as `object` data types. To incorporate these variables into the correlation analysis, we use One Hot Encoding to convert them into numerical format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feature_engine.encoding import OneHotEncoder\n",
        "\n",
        "encoder = OneHotEncoder(variables=df.columns[df.dtypes=='object'].to_list(), drop_last=False)\n",
        "df_ohe = encoder.fit_transform(df)\n",
        "\n",
        "print(df_ohe.shape)\n",
        "df_ohe.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We define a set of functions to calculate and visualize the relationships between variables in the dataset. These functions generate heatmaps for correlation (Pearson and Spearman) and predictive power (PPS), offering insights into both linear, monotonic, and non-linear relationships. To maintain a clean and focused output, we suppress `FutureWarning` messages, which are not critical to the analysis but may clutter the console. The code ensures that the `docs/plots` directory exists, creating it if necessary, so that all generated plots are saved in an organized manner for easy access and future use. For clarity, heatmaps hide values that are 0 or less than 0.2, providing a cleaner and more interpretable visualization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import ppscore as pps\n",
        "import warnings\n",
        "%matplotlib inline\n",
        "\n",
        "# Ignore FutureWarnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "# Theme\n",
        "sns.set_theme(style=\"darkgrid\")\n",
        "\n",
        "# Check and create the folder to save plots\n",
        "def ensure_directory_exists(directory):\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "        print(f\"Directory '{directory}' created.\")\n",
        "\n",
        "# Define correlation heatmap\n",
        "def correlation_heatmap(df, threshold=0.5, figsize=(12, 8), font_size=8, title=\"Correlation Heatmap\", save_path=None):\n",
        "    \"\"\"\n",
        "    Generates a heatmap using correlation, filtering out weak correlations.\n",
        "    \"\"\"\n",
        "    if df.shape[1] > 1:  # Check for enough columns\n",
        "        # Filter rows and columns with values below the threshold\n",
        "        filtered_data = df.loc[(abs(df) >= threshold).any(axis=1), (abs(df) >= threshold).any(axis=0)]\n",
        "\n",
        "        # Create a mask to hide the upper triangle and values that are 0\n",
        "        mask = np.zeros_like(filtered_data, dtype=bool)\n",
        "        mask[np.triu_indices_from(mask)] = True\n",
        "        mask[(abs(filtered_data) <= 0.2)] = True\n",
        "\n",
        "        formatted_data = filtered_data.applymap(lambda x: round(x, 2) if abs(x) > 0.2 else 0)\n",
        "\n",
        "        # Draw heatmap\n",
        "        plt.figure(figsize=figsize)\n",
        "        sns.heatmap(\n",
        "            formatted_data, \n",
        "            annot=True, \n",
        "            cmap=sns.color_palette(\"Spectral\"),\n",
        "            mask=mask, \n",
        "            annot_kws={\"size\": font_size}, \n",
        "            linewidths=0.5\n",
        "        )\n",
        "        plt.title(title)\n",
        "\n",
        "        # Save heatmap\n",
        "        if save_path:\n",
        "            ensure_directory_exists(os.path.dirname(save_path))  # Ensure directory exists\n",
        "            plt.savefig(save_path, bbox_inches='tight')\n",
        "            print(f\"Heatmap saved to {save_path}\")\n",
        "        \n",
        "        plt.show()\n",
        "\n",
        "# Define PPS heatmap\n",
        "def pps_heatmap(df, threshold=0.2, figsize=(12, 8), font_size=8, title=\"PPS Heatmap\", save_path=None):\n",
        "    \"\"\"\n",
        "    Generates a heatmap for PPS matrices, filtering out weak predictive scores.\n",
        "    \"\"\"\n",
        "    if df.shape[1] > 1:  # Check for enough columns\n",
        "        # Filter rows and columns with values under the threshold\n",
        "        filtered_data = df.loc[(abs(df) >= threshold).any(axis=1), (abs(df) >= threshold).any(axis=0)]\n",
        "\n",
        "        # Create a mask to hide values <= 0.2 and values that are exactly 0\n",
        "        mask = np.zeros_like(filtered_data, dtype=bool)\n",
        "        mask[abs(filtered_data) <= 0.2] = True \n",
        "        mask[filtered_data == 0] = True\n",
        "\n",
        "        formatted_data = filtered_data.applymap(lambda x: round(x, 2) if abs(x) > 0.2 else 0)\n",
        "\n",
        "        # Draw heatmap\n",
        "        plt.figure(figsize=figsize)\n",
        "        ax = sns.heatmap(\n",
        "            formatted_data, \n",
        "            annot=True, \n",
        "            cmap=sns.color_palette(\"Spectral\"),\n",
        "            annot_kws={\"size\": font_size}, \n",
        "            linewidths=0.5,\n",
        "            mask=mask\n",
        "        )\n",
        "        # Remove axis titles\n",
        "        ax.set_xlabel('')\n",
        "        ax.set_ylabel('')\n",
        "\n",
        "        plt.title(title)\n",
        "\n",
        "        # Save heatmap\n",
        "        if save_path:\n",
        "            ensure_directory_exists(os.path.dirname(save_path))  # Ensure directory exists\n",
        "            plt.savefig(save_path, bbox_inches='tight')\n",
        "            print(f\"Heatmap saved to {save_path}\")\n",
        "        \n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Correlation Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We start by calculating the Pearson and Spearman correlations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "numeric_df = df.select_dtypes(include=[np.number])\n",
        "spearman_corr = numeric_df.corr(method=\"spearman\")\n",
        "pearson_corr = numeric_df.corr(method=\"pearson\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate heatmaps for Spearman and Pearson methods, hiding values that are 0 or less than 0.2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"*** Spearman heatmap to evaluate monotonic relationships\")\n",
        "correlation_heatmap(\n",
        "    df=spearman_corr,\n",
        "    threshold=0.5,\n",
        "    figsize=(20, 12),\n",
        "    font_size=8,\n",
        "    title=\"Spearman Correlation Heatmap\",\n",
        "    save_path=\"docs/plots/spearman_correlation_heatmap.png\"\n",
        ")\n",
        "print(\"*** Pearson heatmap to evaluate linear relationships\")\n",
        "correlation_heatmap(\n",
        "    df=pearson_corr,\n",
        "    threshold=0.5,\n",
        "    figsize=(20, 12),\n",
        "    font_size=8,\n",
        "    title=\"Pearson Correlation Heatmap\",\n",
        "    save_path=\"docs/plots/pearson_correlation_heatmap.png\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Calculates the Spearman correlation coefficients between the target variable `SalePrice` and all other columns in the `df_ohe` DataFrame, then sorts the results by absolute value in descending order, excluding the self-correlation of `SalePrice`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "spearman_corr = df_ohe.corr(method='spearman')['SalePrice'].sort_values(key=abs, ascending=False)[1:]\n",
        "print(\"Top 10 Spearman correlations with SalePrice:\")\n",
        "spearman_corr.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Calculates the Pearson correlation coefficients between the target variable `SalePrice` and all other columns in the `df_ohe` DataFrame, then sorts the results by absolute value in descending order, excluding the self-correlation of `SalePrice`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pearson_corr = df_ohe.corr(method='pearson')['SalePrice'].sort_values(key=abs, ascending=False)[1:]\n",
        "print(\"\\nTop 10 Pearson correlations with SalePrice:\")\n",
        "print(pearson_corr.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Combine the top 10 attributes from Pearson and Spearman and create a list for further analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "top_n = 10\n",
        "vars_to_study = list(set(pearson_corr.head(top_n).index.to_list() + spearman_corr.head(top_n).index.to_list()))\n",
        "\n",
        "print(\"\\nVariables selected for further study:\")\n",
        "print(vars_to_study)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### PPS Matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Calculate PPS Matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pps_matrix_raw = pps.matrix(df)\n",
        "pps_matrix = pps_matrix_raw.pivot(index='y', columns='x', values='ppscore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Show PPS statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pps_stats = pps_matrix_raw.query(\"ppscore < 1\")['ppscore'].describe()\n",
        "print(\"PPS Statistics:\\n\", pps_stats.round(3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate heatmap for PPS Matrix, hiding values that are 0 or less than 0.2 and save plot to `docs/plots`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"*** PPS Matrix Heatmap to detect both linear and non-linear relationships.\")\n",
        "pps_heatmap(\n",
        "    df=pps_matrix,\n",
        "    threshold=0.2,\n",
        "    figsize=(20, 12),\n",
        "    font_size=8,\n",
        "    title=\"PPS Heatmap\",\n",
        "    save_path=\"docs/plots/pps_heatmap.png\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 4: Exploratory Data Analysis (EDA) on selected variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Combine the top 10 variables from Pearson and Spearman."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "top_n = 10\n",
        "vars_to_study = set(\n",
        "    pearson_corr.head(top_n).index.to_list() +\n",
        "    spearman_corr.head(top_n).index.to_list()\n",
        ")\n",
        "\n",
        "print(\"\\nCombined top 10 variables for further analysis:\")\n",
        "vars_to_study"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We create a new DataFrame (`df_eda`) containing the top attributes along with the target variable `SalePrice`. This makes it easier to use these variables in further analysis or modeling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "selected_features = list(vars_to_study) + ['SalePrice']\n",
        "df_eda = df_ohe[selected_features]\n",
        "\n",
        "df_eda.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We need to understand the distribution of the target variable (`SalePrice`) and identify whether it is skewed or contains outliers. This is important because skewness or outliers can affect the performance of predictive models.\n",
        "\n",
        "We create a histogram with a KDE (Kernel Density Estimate) overlay to visualize the distribution of `SalePrice`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_target_hist(df, target_var):\n",
        "    \"\"\"\n",
        "    Function to plot a histogram of the target variable with KDE overlay.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    sns.histplot(\n",
        "        data=df,\n",
        "        x=target_var,\n",
        "        kde=True,\n",
        "        color=sns.color_palette(\"Spectral\")[0]\n",
        "    )\n",
        "    plt.title(f\"Distribution of {target_var}\", fontsize=20)\n",
        "    plt.xlabel(target_var, fontsize=14)\n",
        "    plt.ylabel(\"Frequency\", fontsize=14)\n",
        "    plt.savefig(f'docs/plots/hist_plot_{target_var}.png', bbox_inches='tight')        \n",
        "    plt.show()\n",
        "\n",
        "# Analyze the distribution of SalePrice\n",
        "plot_target_hist(df_eda, 'SalePrice')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To address **Business Requirement 1**, which is to discover how house attributes correlate with the sale price. This involves performing a bivariate analysis to examine the relationship between each variable in `vars_to_study` and the target variable `SalePrice`.\n",
        "\n",
        "We create three types of visualizations, which help us answer **Business Requirement 1**:\n",
        "* **Linear regression plots** for continuous variables.\n",
        "* **Boxplots** for categorical variables.\n",
        "* **Line plots** for time variables.\n",
        "\n",
        "The function `create_visualizations` automates the process of visualization by iterating through all variables in `vars_to_study` and selecting the appropriate visualization based on the variable type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.set_style('darkgrid')\n",
        "\n",
        "# Time variables\n",
        "time = ['YearBuilt', 'YearRemodAdd']\n",
        "\n",
        "def plot_lm(df, col, target_var):\n",
        "    \"\"\"\n",
        "    Function to create linear regression plots for continuous variables using the Spectral palette.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    scatter = plt.scatter(\n",
        "        x=df[col], \n",
        "        y=df[target_var], \n",
        "        c=df[col], \n",
        "        cmap='Spectral', \n",
        "        alpha=0.7, \n",
        "        edgecolor='k'\n",
        "    )\n",
        "    sns.regplot(\n",
        "        data=df, \n",
        "        x=col, \n",
        "        y=target_var, \n",
        "        scatter=False,\n",
        "        line_kws={'color': 'black'} \n",
        "    )\n",
        "\n",
        "    cbar = plt.colorbar(scatter)\n",
        "    cbar.set_label(f\"{col}\", fontsize=12)\n",
        "\n",
        "    plt.title(f\"Linear Regression Plot: {col} vs {target_var}\", fontsize=14)\n",
        "    plt.xlabel(col, fontsize=8)\n",
        "    plt.ylabel(target_var, fontsize=8)\n",
        "    plt.grid(True, linestyle='--', alpha=0.6)\n",
        "    plt.savefig(f'docs/plots/lm_plot_price_by_{col}.png', bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "def plot_box(df, col, target_var):\n",
        "    \"\"\"\n",
        "    Function to create box plots for categorical variables.\n",
        "    Dynamically adjusts the palette based on the number of categories.\n",
        "    \"\"\"\n",
        "    num_categories = len(df[col].unique()) \n",
        "    palette = sns.color_palette(\"Spectral\", n_colors=num_categories)\n",
        "\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    sns.boxplot(\n",
        "        data=df, \n",
        "        x=col, \n",
        "        y=target_var, \n",
        "        palette=palette\n",
        "    ) \n",
        "    plt.title(f\"{col}\", fontsize=12)\n",
        "    plt.xlabel(col, fontsize=8)\n",
        "    plt.ylabel(target_var, fontsize=8)\n",
        "    plt.savefig(f'docs/plots/box_plot_price_by_{col}.png', bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "def plot_line(df, col, target_var):\n",
        "    \"\"\"\n",
        "    Function to create line plots for time variables.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    sns.lineplot(\n",
        "        data=df, \n",
        "        x=col, \n",
        "        y=target_var, \n",
        "        color=sns.color_palette(\"Spectral\")[1]\n",
        "    )\n",
        "    plt.title(f\"{col}\", fontsize=12)\n",
        "    plt.xlabel(col, fontsize=8)\n",
        "    plt.ylabel(target_var, fontsize=8)\n",
        "    plt.savefig(f'docs/plots/line_plot_price_by_{col}.png', bbox_inches='tight')        \n",
        "    plt.show()\n",
        "\n",
        "# Loop for visualizations\n",
        "def create_visualizations(df, vars_to_study, target_var):\n",
        "    \"\"\"\n",
        "    Loop through variables and create appropriate visualizations.\n",
        "    \"\"\"\n",
        "    for col in vars_to_study:\n",
        "        if len(df[col].unique()) <= 10:  # Categorical variables\n",
        "            plot_box(df, col, target_var)\n",
        "            print(f\"*** Boxplot created for {col}\\n\\n\")\n",
        "        elif col in time:  # Time variables\n",
        "            plot_line(df, col, target_var)\n",
        "            print(f\"*** Line plot created for {col}\\n\\n\")\n",
        "        else:  # Continuous variables\n",
        "            plot_lm(df, col, target_var)\n",
        "            print(f\"*** Linear regression plot created for {col}\\n\\n\")\n",
        "\n",
        "# Call the function to create visualizations\n",
        "create_visualizations(df_eda, vars_to_study, 'SalePrice')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "## Conclusions and Next Steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Conclusions\n",
        "We successfully completed the correlation analysis and visualization process, identifying key predictors for modeling and validating hypotheses related to house prices.\n",
        "\n",
        "#### Key observations include\n",
        "1. **Size Matters**: Larger properties, as indicated by variables like `1stFlrSF`, `GrLivArea`, `TotalBsmtSF`, and `GarageArea`, are associated with higher sale prices.\n",
        "2. **Time Matters**: Recently built houses (`YearBuilt`) and houses with recent remodels (`YearRemodAdd`) tend to have higher sale prices.\n",
        "3. **Quality Matters**: Higher overall quality (`OverallQual`) and kitchen quality (`KitchenQual`) ratings are strongly correlated with higher sale prices.\n",
        "\n",
        "All visualizations were saved in the `docs/plots` directory for further use in the Streamlit app and to meet **Business Requirement 1**.\n",
        "\n",
        "### Next steps: Feature Engineering\n",
        "1. **Handle outliers**: Identify and address outliers in key variables like `GrLivArea`, `TotalBsmtSF`, and `GarageArea` to improve model robustness.\n",
        "2. **Transform Variables**: Apply log transformation to `SalePrice` and other skewed variables to enhance linearity.\n",
        "3. **Create New Features**: Combine existing variables to create new features.\n",
        "4. **Scale Data**: Standardize or normalize numerical variables to ensure consistent scaling for modeling."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
